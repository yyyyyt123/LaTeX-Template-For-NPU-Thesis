\chapter{MoE模型训练过程概述}

MoE模型在原本Transformer block的FFN中通过添加门控函数以及一系列相互并列的专家组成。
% 
在训练过程中门控函数主要将输入数据分配给不同的专家模型参与前向/反向计算，这一过程主要通过All-to-All通信实现。
% 
待每个专家计算完成相对应的数据之后，我们需要通过一次额外的All-to-All通信，将计算完成的激活值返回原本对应的GPU上，并参与后续的计算过程。

\section{MoE模型的分布式训练}

\begin{figure}[h!]
    \vskip 2ex
    \centering
    \includegraphics[width=0.99\linewidth]{figures/fig2.png}
    \caption{MoE模型训练过程}
    \label{fig-moe-arch}
    \end{figure}

图\ref{fig-moe-arch}展示了传统的集中式的Transformer模型训练过程转变到分布式的Transformer-MoE训练过程的示意图。
% 
绿色的部分是增加的门控函数，用于决定将数据分派至哪一个expert参与计算，红色部分的$\mathbf{FFN_1-FFN_E}$表示该层中具有E个互相独立的专家个数。
% 
由于GPU的显存有限，不能将所有的专家的参数都在一张GPU中保存下。
% 
因此GShard\ucite{lepikhin2020gshard}的研究者们提出了专家并行的概念，将每个专家的参数单独放置在GPU上，其他部分采用数据并行的架构，从而实现了一种混合的分布式训练过程。
% 
在训练过程结束之后，通常需要额外的All-reduce用于同步数据并行模块的梯度，最后根据每个可训练参数的梯度，调用优化器更新参数。

整体的训练流程总结如下：

\begin{itemize}

    \item \textbf{1.数据划分}
    
每个GPU将训练数据随机筛选，确保每一轮训练中每个GPU上包含的数据子集是互不重复的。
% 
每个子集分配到不同的GPU或计算节点上进行训练。
    
    \item \textbf{2.数据并行\&专家并行}
    
在MoE模型训练中，数据并行和专家并行通常结合使用，以实现更高效的分布式训练。
% 
具体而言，可以将训练数据划分为多个子集，并将每个子集分配到不同的GPU或计算节点上。
% 
在每个GPU或计算节点上，可以使用专家并行的方式对每个专家模型进行训练，同时使用数据并行的方式对整个MoE模型进行训练。
% 
这样可以将计算负载和数据负载都分散到多个GPU或计算节点上，从而加速整个MoE模型的训练过程。

    \item \textbf{3.前向传播}
    
    每一层的前向传播主要在以下两个步骤区别与传统的密集型Transformer计算。（数据分派和专家计算）。

在数据分派阶段，MoE模型使用Gating门函数对每个输入数据进行加权打分，以决定每个专家模型的贡献。这个Gating函数由一层MLP和softmax组成。具体而言，MoE模型将输入$x$输入到门控模型中，得到一个$E$维的得分，$f=[f_1,f_2,\cdots,f_E]$， $f_i$表示第$i$个专家模型的权重得分。门控向量的每个元素都是非负的，并且它们的和等于1，即$\sum_{i=1}^K g_i = 1$。最后通过全局所有GPU的All-to-All通信，将对应数据发送给相应的GPU，参与后续的计算。

专家计算阶段，每个GPU上接收到其他GPU传输来的数据后（假设有d维），将其输入相应的专家模型参与前向计算。
% 
得到d维的输出向量$r$。之后通过反向的All-to-All通信，将激活值返回对应的GPU上，得到每个GPU上原本数据的输出向量$z=[z_1,z_2,\cdots,z_E]$。
% 
然后，MoE模型将每个输出向量$z_i$与对应的门控向量$g_i$进行按元素乘法，得到一个加权输出向量$w$，其中$w_{i}=g_{i}z_{i}$。最后，MoE模型将所有加权输出向量$w_i$进行累加，得到最终的输出向量$y$，其中$y=\sum_{i=1}^E w_{i}$。

    \item \textbf{4.反向传播}
    
    是用于计算MoE模型的梯度，其过程类似于传统的神经网络模型。
    % 
    在完成前向传播计算之后，使用PyTorch的自动求导机制（autograd）建立计算图，并自动计算每个参数的梯度。
    % 
    具体而言，可以使用loss函数对模型的输出进行评估，并计算输出和目标值之间的误差。
    % 
    然后，使用误差及其对模型参数的导数，计算每个参数的梯度。
    % 
    反向传播过程可以使用链式法则（chain rule）实现，即将误差从输出层向输入层传播，并依次计算每个参数的梯度。

    \item \textbf{5.梯度计算}
    
    是将每个模型的梯度进行同步，以便在参数更新时使用。
    % 
    由于MoE模型的分布式训练过程涉及多个GPU或计算节点的并行计算，因此需要使用all-reduce等方法将所有模型的梯度进行同步。

    \item \textbf{6.参数更新}
    
    使用优化器对模型参数进行更新，以最小化损失函数。在MoE模型训练中，可以使用常见的优化器，如Adam、SGD等，对每个模型的参数进行更新。
    % 
    通常，参数更新的速率会受到学习率（learning rate）等超参数的控制，以平衡模型的收敛速度和稳定性。

    \item \textbf{7.重复迭代}
    
    将以上步骤重复多次，直到模型收敛为止。在每次迭代中，可以使用不同的训练数据子集，防止模型陷入局部最优解。

\end{itemize}

\section{MoE训练瓶颈分析}

在GPU集群中分布式训练MoE模型时，我们首先测量分析了一些已有训练系统存在的缺陷和问题，这些挑战会极大地影响训练效率。

\begin{table}[]
    \centering
    \label{table-moti}
    \caption{使用Transformer-xl~\ucite{dai2019transformer}语言模型再不同模型设计下的All-to-All通信时间与每个训练阶段完成时间。每个FFN层都使用MoE替代，且专家的数量等于GPU的数量。}
\begin{tabular}{ccccc}
\hline
\cellcolor[HTML]{FFFFFF}\#Experts & Model      & All-to-All & Step Time & Ratio                           \\ \hline
                                  & 8L + 94M   & 259        & 722       & \cellcolor[HTML]{FFFFFF}35.80\% \\
                                  & 12L + 117M & 589        & 1684      & \cellcolor[HTML]{FFFFFF}34.90\% \\
\multirow{-3}{*}{4}               & 24L + 233M & 1479       & 3894      & \cellcolor[HTML]{FFFFFF}37.80\% \\ \hline
\end{tabular}
    \end{table}



\noindent \textbf{All-to-All通信效率低}
MoE模型的训练瓶颈之一是All-to-All通信，这是由于模型中多个专家模型之间需要进行信息交换所导致的。之前的工作已经确定了All-to-All通信是MoE模型训练的一个瓶颈~\ucite{he2021fastmoe,hwang2022tutel,li2023accelerating}。表2-1显示了在我们的GPU集群中各种语言模型的训练步骤时间以及All-to-All操作的完成时间。平均而言，All-to-All操作占用了37.4\%的步进时间，这是很大一部分。在下文中，我们通过剖析MoE中All-to-All通信成本的主要原因来引入我们的工作。我们的分析基于专家数量与(GPU)设备数量相同的常见场景。

首先，All-to-All操作是同步操作，会阻塞计算过程。图\ref{fig-moe-arch}显示了集群中MoE模型训练前向传递的流程图。我们观察到专家的FFN计算和组合操作仅在All-to-All操作完成时发生。在此期间，GPU大部分处于空闲状态。我们使用PyTorch Profiler对表2-1中每个实验中20个步骤的GPU活动进行了分析，并发现这种空闲状态很明显。在MoE模型的前向传递中，会使用两个All-to-All操作，一个用于将标记从之前的Add \& Norm层输出结果路由到选择的专家，另一个用于在专家计算后将它们发送回其原始GPU。因此，一个MoE层的完整训练步骤将涉及四个All-to-All操作，其中两个来自反向传递。这加剧了MoE模型训练的低效率问题。

其次MoE训练过程瓶颈的第二个原因是其庞大的数据传输规模。
由于专家的FFN架构确保其输入数据大小与输出数据大小相同，因此前向传递的两个All-to-All操作中的数据传输具有相同的大小。
数据传输的大小由每个GPU的\textit{batch\_size}、专家（或GPU）的数量N、序列长度\textit{seq\_len}, 如top-k中的k(所选专家的数量)以及编码器,解码器输入\textit{d\_model}中的特征大小决定。

\section{本章小结}

本章我们主要分析了现有的MoE模型训练过程，MoE模型的训练过程通常比传统的神经网络模型更为复杂和耗时，需要充分利用分布式计算和并行计算等技术，以提高训练速度和效率。
% 
同时，MoE模型的设计和调整也需要考虑多个因素，如门控模型的设计、专家模型的选择和训练方式等，以提高模型的性能和泛化能力。

\endinput