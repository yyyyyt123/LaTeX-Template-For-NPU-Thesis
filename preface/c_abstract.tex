\renewcommand{\baselinestretch}{1.5}
\fontsize{12pt}{13pt}\selectfont

% \addtocontents{toc}{\protect\setcounter{tocdepth}{-1}}
\chapter[摘要]{摘~~~~要}
\markboth{中~文~摘~要}{中~文~摘~要}

本文工作致力于提出一种面向MoE（混合专家）模型的高效分布式训练框架，旨在加速和优化大规模模型的训练过程。MoE模型是一种强大的深度学习模型，但其训练过程常常受限于计算和通信的瓶颈。为了解决这些问题，在Deepspeed分布式深度学习框架的基础上，提出了两个创新点：动态路由的数据分派方式和基于网络拓扑的负载均衡策略。

首先，引入了动态路由的数据分派方式，旨在优化数据在MoE模型中的分配过程。传统的Top-1和Top-2 Gating策略在数据分派中存在一定的局限性，无法充分利用专家模型的容量和多样性。我们提出了一种动态路由策略，根据数据的特征和模型的权重动态地选择适合的专家进行计算，从而实现更好的数据分派和利用。

其次，设计了基于网络拓扑的负载均衡策略，以优化训练阶段全局通信与后续计算并行性较差的问题。在传统的MoE并行训练中，需要通过全局的All-to-All通信不同GPU上的数据，这一过程过程常常成为性能瓶颈，尤其是在大规模模型和分布式环境中。我们通过分析GPU集群的拓扑结构，提出了一种智能的负载均衡策略，根据网络拓扑信息调整专家的分配和数据的路由，以减少通信开销并提高整体性能。

进行了一系列实验来评估我们的设计。我们在中小规模GPU集群中开展真实实验。在前向和反向传播阶段，我们设计的训练系统显至多可以提升4倍训练速度，并且可以有效利用了数据的多样性。然而，在梯度同步阶段，由于更复杂的通信模式，性能有所下降。整体端到端的实验结果表明我们设计的策略能够更均衡地分配计算负载，减少通信瓶颈，提高整体训练性能。

综上, 本文主要贡献有
\vspace{-10pt}
\begin{enumerate}
    \item 分析现有MoE训练框架的不足
    \item 提出了基于动态路由的数据分派方式
    \item 设计了基于网络拓扑的负载均衡策略
    \item 开展了真实系统的实验，验证提出方案的性能
\end{enumerate}
\vspace{-10pt}

\vspace{1em}
\noindent {\fHei{关键词:}~} \quad 混合专家模型，深度学习分布式训练系统, 动态负载均衡算法

% \clearpage
\endinput
